{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os import remove\n",
    "import pickle\n",
    "from os.path import join\n",
    "from src.modules.filestructure import PklPath, OutputPath, RunLib, RunDataImporter\n",
    "\n",
    "RunLib, RunDataImporter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a0fc0",
   "metadata": {},
   "source": [
    "# Backing up the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b0f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $RunLib.db_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear files (this deletes files on the system)\n",
    "pkl_files = glob(f\"{PklPath.data_importer}/*.pkl\")\n",
    "db_files = glob(f\"{PklPath.db}/*.pkl\")\n",
    "sql_files = glob(f\"{OutputPath.sql}/*.sql\")\n",
    "\n",
    "if pkl_files or sql_files:\n",
    "    delete_files = (\n",
    "        input(\n",
    "            f\"Are you sure you want to delete files in\\n{PklPath.data_importer} and \\n{OutputPath.sql} ? (y/n)\"\n",
    "        ).lower()\n",
    "        == \"y\"\n",
    "    )\n",
    "    if not delete_files:\n",
    "        raise Exception(\"Your files were not deleted\")\n",
    "else:\n",
    "    print(\"No files were found\")\n",
    "\n",
    "for item in [pkl_files, db_files, sql_files]:\n",
    "    if item and delete_files:\n",
    "        try:\n",
    "            for temp in item:\n",
    "                remove(temp)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca94ac",
   "metadata": {},
   "source": [
    "# Adding pk to tables\n",
    "We will just run 4_Pk_PersonInfo first so that the foreign key constraint will be fulfilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $RunDataImporter.file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $RunDataImporter.file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2584ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $RunDataImporter.file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $RunDataImporter.file4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO make sql code updates from within here. I need to find a way to deal with problems and resuming updates\n",
    "# TODO: make all updates in a single statement for the sake of speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34deae26",
   "metadata": {},
   "source": [
    "# removing rows that only have primary keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70439ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    RunLib  # this is just so that the import statement doesn't get removed\n",
    "    %run $RunLib.db_query\n",
    "except Exception:\n",
    "    print(\n",
    "        \"Error:\\nFalling back to previously created pickle files.\\nCheck ReadMe_history.txt for more information.\"\n",
    "    )\n",
    "\n",
    "# Relation dictionary\n",
    "with open(join(PklPath.db, \"pk_schema.pkl\"), \"rb\") as pickle_in:\n",
    "    pk_schema = pickle.load(pickle_in)\n",
    "\n",
    "with open(join(PklPath.db, \"db_schema.pkl\"), \"rb\") as pickle_in:\n",
    "    db_schema = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96d9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this if the db schema changed, otherwise use the one in \"Do Not Delete\" folder\n",
    "\n",
    "# ignore_col = set(['AnalysisType', 'GalectinSpecimenType'])\n",
    "# for tableName in set(pk_schema.loc[:,'table_name']):\n",
    "#     pk_col = set(pk_schema[pk_schema['table_name'] == tableName].loc[:,'col_name'])\n",
    "#     col = set(db_schema[db_schema['table_name'] == tableName].loc[:,'col_name'])\n",
    "#     null_col = col - pk_col\n",
    "#\n",
    "#     preText: str = f\"DELETE FROM HealthProject.{tableName} WHERE\\n\"\n",
    "#     values:str = \"\"\n",
    "#\n",
    "#     for header in null_col:\n",
    "#         values = values + f'{header} IS null AND \\n'\n",
    "#\n",
    "#     final_statement = f'{preText}{values[:-6]};\\n\\n'\n",
    "#\n",
    "#     with open (f'../../outputData/5_removeNull.sql', 'a') as file:\n",
    "#         file.write(final_statement)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "notebooks//ipynb,_notebooks//py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
